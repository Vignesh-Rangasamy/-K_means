Project Title:
Implementation and Evaluation of K-Means Clustering from Scratch

Objective:
The objective of this project is to implement the K-Means clustering algorithm
from scratch using NumPy and to compare its performance with the K-Means
implementation provided by the scikit-learn library. The comparison focuses on
cluster quality using the Within-Cluster Sum of Squares (WCSS) metric.

Dataset Description:
A synthetic two-dimensional dataset was generated using the make_blobs function.
The dataset contains 300 data points distributed across three clusters with a
cluster standard deviation of 1.2. This dataset provides clear separation
between clusters and is suitable for evaluating clustering performance.

Initialization Strategy:
The custom K-Means implementation uses basic random initialization. Initial
centroids are selected randomly from the dataset without replacement. Advanced
initialization strategies such as K-Means++ were not implemented in the custom
algorithm. Scikit-learn's KMeans uses K-Means++ by default, which can lead to
better initial centroid placement.

Methodology:
The custom K-Means algorithm follows the standard iterative approach:
1. Random selection of initial centroids.
2. Calculation of Euclidean distance between data points and centroids.
3. Assignment of points to the nearest centroid.
4. Update of centroids using the mean of assigned points.
5. Repetition until convergence or until the maximum number of iterations
   is reached.

The implementation also handles empty clusters by reinitializing the centroid
with a randomly selected data point.

Results:
The clustering performance was evaluated using the Within-Cluster Sum of Squares
(WCSS) metric.

WCSS (Custom K-Means):816.2777536191549
WCSS (Scikit-Learn):816.2777536191547

Conclusion:
The results show that the custom implementation achieved a WCSS value nearly
identical to that of the scikit-learn implementation. This indicates that the
custom K-Means algorithm converged to a high-quality clustering solution despite
using basic random initialization. The project demonstrates that a correctly
implemented K-Means algorithm from scratch can achieve performance comparable
to a standard machine learning library.
