Final WCSS Value (Custom K-Means):
816.2777536191549

Analysis and Interpretation:

The custom K-Means implementation uses standard random initialization for
centroid selection, whereas scikit-learnâ€™s KMeans employs the K-Means++
initialization strategy. K-Means++ improves centroid placement by spreading
initial centroids farther apart, which often leads to faster convergence and
slightly lower WCSS values.

Despite this difference in initialization, both algorithms converged to
almost identical final WCSS values. The extremely small difference between
the two results is primarily due to floating-point arithmetic and minor
differences in centroid initialization paths rather than differences in
cluster quality.

In terms of convergence behavior, the scikit-learn implementation typically
reaches convergence in fewer iterations due to its optimized initialization
and internal numerical optimizations written in C. The custom implementation,
while potentially requiring slightly more iterations, still converges
reliably and produces stable centroids.

Visual inspection of the clustering results confirms that both approaches
identify well-separated and compact clusters, with centroids positioned near
the center of each cluster. The handling of empty clusters in the custom
implementation further improves robustness and prevents numerical instability.

Overall, this analysis demonstrates that although library implementations may
offer faster convergence and optimized initialization, a correctly implemented
K-Means algorithm from scratch can achieve equivalent clustering performance
and produce comparable final results.
